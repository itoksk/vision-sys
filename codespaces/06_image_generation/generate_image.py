#!/usr/bin/env python3
"""
AIç”»åƒç”Ÿæˆã‚¹ã‚¯ãƒªãƒ—ãƒˆï¼ˆStable Diffusionï¼‰
å·¥æ¥­é«˜æ ¡ç”Ÿå‘ã‘ç”»åƒç”Ÿæˆå®Ÿç¿’
"""

import os
import sys
import argparse
from datetime import datetime
import torch
from diffusers import StableDiffusionPipeline, DPMSolverMultistepScheduler
import warnings
warnings.filterwarnings("ignore")

# åˆ©ç”¨å¯èƒ½ãªãƒ¢ãƒ‡ãƒ«
MODELS = {
    "anything-v5": {
        "id": "stablediffusionapi/anything-v5",
        "name": "Anything V5ï¼ˆã‚¢ãƒ‹ãƒ¡ãƒ»ã‚¤ãƒ©ã‚¹ãƒˆï¼‰",
        "description": "å¹…åºƒã„ã‚¢ãƒ‹ãƒ¡ã‚¹ã‚¿ã‚¤ãƒ«ã«å¯¾å¿œ",
        "prompt_tips": "best quality, ultra detailed, masterpiece"
    },
    "counterfeit-v3": {
        "id": "gsdf/Counterfeit-V3.0",
        "name": "Counterfeit V3.0ï¼ˆé«˜å“è³ªã‚¢ãƒ‹ãƒ¡ï¼‰",
        "description": "ç¾éº—ãªã‚¢ãƒ‹ãƒ¡ã‚¤ãƒ©ã‚¹ãƒˆç”Ÿæˆ",
        "prompt_tips": "best quality, masterpiece, ultra-detailed"
    },
    "realistic-vision": {
        "id": "SG161222/Realistic_Vision_V6.0_B1_noVAE",
        "name": "Realistic Vision V6.0ï¼ˆå†™å®Ÿçš„ï¼‰",
        "description": "ãƒ•ã‚©ãƒˆãƒªã‚¢ãƒªã‚¹ãƒ†ã‚£ãƒƒã‚¯ãªç”»åƒ",
        "prompt_tips": "RAW photo, best quality, realistic, photo-realistic"
    },
    "dreamshaper": {
        "id": "Lykon/DreamShaper",
        "name": "DreamShaperï¼ˆå¤šç›®çš„ï¼‰",
        "description": "å¹…åºƒã„ã‚¹ã‚¿ã‚¤ãƒ«ã«å¯¾å¿œ",
        "prompt_tips": "highly detailed, 8k, best quality"
    }
}

class ImageGenerator:
    def __init__(self, model_name="anything-v5", device="cuda"):
        """ç”»åƒç”Ÿæˆå™¨ã‚’åˆæœŸåŒ–"""
        self.model_name = model_name
        self.model_info = MODELS[model_name]
        
        # ãƒ‡ãƒã‚¤ã‚¹ã‚’è¨­å®š
        if device == "cuda" and not torch.cuda.is_available():
            print("âš ï¸  GPUãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚CPUã‚’ä½¿ç”¨ã—ã¾ã™ï¼ˆé…ã„å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ï¼‰")
            self.device = "cpu"
        else:
            self.device = device
        
        print(f"ğŸ¨ ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã¿ä¸­: {self.model_info['name']}")
        print(f"   {self.model_info['description']}")
        
        # ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’åˆæœŸåŒ–
        self.pipe = StableDiffusionPipeline.from_pretrained(
            self.model_info['id'],
            torch_dtype=torch.float16 if self.device == "cuda" else torch.float32,
            safety_checker=None,
            requires_safety_checker=False
        )
        
        # ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ã‚’è¨­å®šï¼ˆé«˜é€ŸåŒ–ï¼‰
        self.pipe.scheduler = DPMSolverMultistepScheduler.from_config(
            self.pipe.scheduler.config
        )
        
        # ãƒ‡ãƒã‚¤ã‚¹ã«ç§»å‹•
        self.pipe = self.pipe.to(self.device)
        
        # ãƒ¡ãƒ¢ãƒªæœ€é©åŒ–
        if self.device == "cuda":
            self.pipe.enable_attention_slicing()
        
        print("âœ… ãƒ¢ãƒ‡ãƒ«ã®æº–å‚™ãŒå®Œäº†ã—ã¾ã—ãŸ")
    
    def generate(self, prompt, negative_prompt="", width=512, height=512, 
                 steps=20, guidance_scale=7.5, seed=None):
        """ç”»åƒã‚’ç”Ÿæˆ"""
        # ã‚·ãƒ¼ãƒ‰ã‚’è¨­å®š
        if seed is not None:
            generator = torch.Generator(device=self.device).manual_seed(seed)
        else:
            generator = None
        
        # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’å¼·åŒ–
        enhanced_prompt = f"{prompt}, {self.model_info['prompt_tips']}"
        
        print(f"\nğŸ¨ ç”»åƒã‚’ç”Ÿæˆä¸­...")
        print(f"ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ: {enhanced_prompt}")
        print(f"ã‚µã‚¤ã‚º: {width}x{height}, ã‚¹ãƒ†ãƒƒãƒ—æ•°: {steps}")
        
        # ç”»åƒã‚’ç”Ÿæˆ
        result = self.pipe(
            prompt=enhanced_prompt,
            negative_prompt=negative_prompt,
            width=width,
            height=height,
            num_inference_steps=steps,
            guidance_scale=guidance_scale,
            generator=generator
        )
        
        return result.images[0]

def create_prompt_examples():
    """ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆä¾‹ã‚’è¡¨ç¤º"""
    examples = {
        "å·¥æ¥­éƒ¨å“": {
            "prompt": "industrial metal part, gear mechanism, precise engineering, technical drawing style",
            "negative": "blur, rust, damage"
        },
        "å‚·ã®ã‚ã‚‹éƒ¨å“": {
            "prompt": "metal surface with scratch, defect inspection, close-up photography, industrial quality control",
            "negative": "perfect, flawless"
        },
        "å·¥å ´ã®é¢¨æ™¯": {
            "prompt": "modern factory interior, automated production line, industrial robots, clean environment",
            "negative": "dirty, old, abandoned"
        },
        "å“è³ªæ¤œæŸ»": {
            "prompt": "quality inspection process, worker examining parts, magnifying glass, bright lighting",
            "negative": "dark, unclear"
        },
        "AIãƒ­ãƒœãƒƒãƒˆ": {
            "prompt": "futuristic AI robot inspector, examining industrial parts, high-tech factory setting",
            "negative": "old technology, broken"
        }
    }
    
    print("\nğŸ“ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆä¾‹:")
    print("=" * 60)
    for name, ex in examples.items():
        print(f"\nã€{name}ã€‘")
        print(f"ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ: {ex['prompt']}")
        print(f"ãƒã‚¬ãƒ†ã‚£ãƒ–: {ex['negative']}")
    print("=" * 60)

def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    parser = argparse.ArgumentParser(
        description="AIç”»åƒç”Ÿæˆãƒ„ãƒ¼ãƒ«ï¼ˆStable Diffusionï¼‰"
    )
    parser.add_argument(
        "--prompt",
        type=str,
        help="ç”Ÿæˆã—ãŸã„ç”»åƒã®èª¬æ˜ï¼ˆè‹±èªæ¨å¥¨ï¼‰"
    )
    parser.add_argument(
        "--negative",
        type=str,
        default="low quality, blurry, bad anatomy",
        help="ç”Ÿæˆã—ãŸããªã„è¦ç´ "
    )
    parser.add_argument(
        "--model",
        choices=list(MODELS.keys()),
        default="anything-v5",
        help="ä½¿ç”¨ã™ã‚‹ãƒ¢ãƒ‡ãƒ«"
    )
    parser.add_argument(
        "--width",
        type=int,
        default=512,
        help="ç”»åƒã®å¹…ï¼ˆ512æ¨å¥¨ï¼‰"
    )
    parser.add_argument(
        "--height",
        type=int,
        default=512,
        help="ç”»åƒã®é«˜ã•ï¼ˆ512æ¨å¥¨ï¼‰"
    )
    parser.add_argument(
        "--steps",
        type=int,
        default=20,
        help="ç”Ÿæˆã‚¹ãƒ†ãƒƒãƒ—æ•°ï¼ˆå¤šã„ã»ã©é«˜å“è³ªã ãŒé…ã„ï¼‰"
    )
    parser.add_argument(
        "--seed",
        type=int,
        help="ä¹±æ•°ã‚·ãƒ¼ãƒ‰ï¼ˆåŒã˜ç”»åƒã‚’å†ç¾ã—ãŸã„å ´åˆï¼‰"
    )
    parser.add_argument(
        "--output",
        type=str,
        help="å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«å"
    )
    parser.add_argument(
        "--list-models",
        action="store_true",
        help="åˆ©ç”¨å¯èƒ½ãªãƒ¢ãƒ‡ãƒ«ä¸€è¦§ã‚’è¡¨ç¤º"
    )
    parser.add_argument(
        "--examples",
        action="store_true",
        help="ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆä¾‹ã‚’è¡¨ç¤º"
    )
    
    args = parser.parse_args()
    
    print("ğŸ¨ AIç”»åƒç”Ÿæˆãƒ„ãƒ¼ãƒ«")
    print("=" * 60)
    
    # ãƒ¢ãƒ‡ãƒ«ä¸€è¦§ã‚’è¡¨ç¤º
    if args.list_models:
        print("\nåˆ©ç”¨å¯èƒ½ãªãƒ¢ãƒ‡ãƒ«:")
        for key, info in MODELS.items():
            print(f"\n{key}:")
            print(f"  åå‰: {info['name']}")
            print(f"  èª¬æ˜: {info['description']}")
        return
    
    # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆä¾‹ã‚’è¡¨ç¤º
    if args.examples:
        create_prompt_examples()
        return
    
    # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãŒæŒ‡å®šã•ã‚Œã¦ã„ãªã„å ´åˆ
    if not args.prompt:
        print("\nâš ï¸  ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’æŒ‡å®šã—ã¦ãã ã•ã„")
        print("\nä½¿ç”¨ä¾‹:")
        print("  python generate_image.py --prompt \"industrial robot\" --output robot.png")
        print("\nãƒ—ãƒ­ãƒ³ãƒ—ãƒˆä¾‹ã‚’è¦‹ã‚‹:")
        print("  python generate_image.py --examples")
        return
    
    # å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«åã‚’ç”Ÿæˆ
    if not args.output:
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        args.output = f"generated_{timestamp}.png"
    
    # ç”»åƒç”Ÿæˆå™¨ã‚’åˆæœŸåŒ–
    generator = ImageGenerator(args.model)
    
    # ç”»åƒã‚’ç”Ÿæˆ
    try:
        image = generator.generate(
            prompt=args.prompt,
            negative_prompt=args.negative,
            width=args.width,
            height=args.height,
            steps=args.steps,
            seed=args.seed
        )
        
        # ä¿å­˜
        image.save(args.output)
        print(f"\nâœ… ç”»åƒã‚’ä¿å­˜ã—ã¾ã—ãŸ: {args.output}")
        
        # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚‚ä¿å­˜
        metadata = {
            "prompt": args.prompt,
            "negative_prompt": args.negative,
            "model": args.model,
            "size": f"{args.width}x{args.height}",
            "steps": args.steps,
            "seed": args.seed,
            "timestamp": datetime.now().isoformat()
        }
        
        import json
        metadata_file = args.output.replace('.png', '_metadata.json')
        with open(metadata_file, 'w', encoding='utf-8') as f:
            json.dump(metadata, f, ensure_ascii=False, indent=2)
        
        print(f"ğŸ“„ ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜: {metadata_file}")
        
    except Exception as e:
        print(f"\nâŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        print("\nãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°:")
        print("1. GPUãƒ¡ãƒ¢ãƒªä¸è¶³ã®å ´åˆ: --width 512 --height 512 ã‚’æŒ‡å®š")
        print("2. ãƒ¢ãƒ‡ãƒ«ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãŒé…ã„å ´åˆ: ã—ã°ã‚‰ãå¾…ã£ã¦ãã ã•ã„")
        print("3. CUDAã‚¨ãƒ©ãƒ¼ã®å ´åˆ: CPUãƒ¢ãƒ¼ãƒ‰ã§å®Ÿè¡Œã•ã‚Œã¾ã™")

if __name__ == "__main__":
    main()