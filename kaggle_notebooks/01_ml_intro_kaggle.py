#!/usr/bin/env python
# -*- coding: utf-8 -*-

"""
æ©Ÿæ¢°å­¦ç¿’å…¥é–€ - Kaggle Notebookç‰ˆ
VGG16ã«ã‚ˆã‚‹ç”»åƒåˆ†é¡ã¨YOLO/OpenCVã«ã‚ˆã‚‹äººç‰©æ¤œå‡º
"""

import os
import sys
import numpy as np
import matplotlib.pyplot as plt
from PIL import Image
import cv2

# TensorFlow/Keras
import tensorflow as tf
from tensorflow.keras.applications import VGG16
from tensorflow.keras.preprocessing import image
from tensorflow.keras.applications.vgg16 import preprocess_input, decode_predictions
from tensorflow.keras.models import Model

# YOLO
try:
    from ultralytics import YOLO
    YOLO_AVAILABLE = True
except:
    print("âš ï¸ YOLOãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚OpenCVã®ã¿ã§äººç‰©æ¤œå‡ºã‚’è¡Œã„ã¾ã™ã€‚")
    YOLO_AVAILABLE = False

print("ğŸš€ æ©Ÿæ¢°å­¦ç¿’å…¥é–€ - Kaggle Notebookç‰ˆ")
print("=" * 50)

# Kaggleã§ã®ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹è¨­å®š
KAGGLE_INPUT_DIR = '/kaggle/input'
KAGGLE_WORKING_DIR = '/kaggle/working'

def find_input_images():
    """Kaggleã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸç”»åƒã‚’æ¢ã™"""
    image_files = []
    image_extensions = {'.jpg', '.jpeg', '.png', '.bmp'}
    
    for root, dirs, files in os.walk(KAGGLE_INPUT_DIR):
        for file in files:
            if os.path.splitext(file.lower())[1] in image_extensions:
                image_files.append(os.path.join(root, file))
    
    if image_files:
        print(f"\nğŸ“· è¦‹ã¤ã‹ã£ãŸç”»åƒãƒ•ã‚¡ã‚¤ãƒ«:")
        for img in image_files:
            print(f"  - {img}")
    else:
        print("\nâš ï¸ ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
        print("å³å´ã®ã€ŒAdd dataã€ã‹ã‚‰ç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")
    
    return image_files

def vgg16_classification(image_path):
    """VGG16ã«ã‚ˆã‚‹ç”»åƒåˆ†é¡"""
    print(f"\nğŸ” VGG16ã«ã‚ˆã‚‹ç”»åƒåˆ†é¡: {os.path.basename(image_path)}")
    
    # ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã‚€
    model = VGG16(weights='imagenet')
    
    # ç”»åƒã‚’èª­ã¿è¾¼ã‚“ã§å‰å‡¦ç†
    img = image.load_img(image_path, target_size=(224, 224))
    x = image.img_to_array(img)
    x = np.expand_dims(x, axis=0)
    x = preprocess_input(x)
    
    # äºˆæ¸¬
    predictions = model.predict(x)
    results = decode_predictions(predictions, top=5)[0]
    
    # çµæœã‚’è¡¨ç¤º
    print("\näºˆæ¸¬çµæœï¼ˆä¸Šä½5ä»¶ï¼‰:")
    for i, (imagenet_id, label, score) in enumerate(results):
        print(f"{i+1}. {label}: {score*100:.2f}%")
    
    # çµæœã‚’å¯è¦–åŒ–
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))
    
    # å…ƒç”»åƒ
    ax1.imshow(img)
    ax1.set_title(f"å…¥åŠ›ç”»åƒ: {os.path.basename(image_path)}")
    ax1.axis('off')
    
    # äºˆæ¸¬çµæœã®æ£’ã‚°ãƒ©ãƒ•
    labels = [r[1] for r in results]
    scores = [r[2] * 100 for r in results]
    
    ax2.barh(range(5), scores)
    ax2.set_yticks(range(5))
    ax2.set_yticklabels(labels)
    ax2.set_xlabel('ç¢ºç‡ (%)')
    ax2.set_title('VGG16 äºˆæ¸¬çµæœ')
    ax2.set_xlim(0, 100)
    
    plt.tight_layout()
    output_path = os.path.join(KAGGLE_WORKING_DIR, f'vgg16_result_{os.path.basename(image_path)}')
    plt.savefig(output_path, dpi=150, bbox_inches='tight')
    plt.show()
    
    return results

def visualize_feature_maps(image_path):
    """ç‰¹å¾´ãƒãƒƒãƒ—ã®å¯è¦–åŒ–"""
    print(f"\nğŸ¨ ç‰¹å¾´ãƒãƒƒãƒ—ã®å¯è¦–åŒ–")
    
    # VGG16ãƒ¢ãƒ‡ãƒ«ã®ä¸€éƒ¨ã‚’å–ã‚Šå‡ºã™
    base_model = VGG16(weights='imagenet', include_top=False)
    model = Model(inputs=base_model.input, outputs=base_model.get_layer('block2_conv2').output)
    
    # ç”»åƒã‚’èª­ã¿è¾¼ã‚“ã§å‰å‡¦ç†
    img = image.load_img(image_path, target_size=(224, 224))
    x = image.img_to_array(img)
    x = np.expand_dims(x, axis=0)
    x = preprocess_input(x)
    
    # ç‰¹å¾´ãƒãƒƒãƒ—ã‚’å–å¾—
    features = model.predict(x)
    
    # å¯è¦–åŒ–
    fig, axes = plt.subplots(4, 4, figsize=(12, 12))
    for i, ax in enumerate(axes.flat):
        if i < 16:
            ax.imshow(features[0, :, :, i], cmap='viridis')
            ax.set_title(f'Filter {i+1}')
        ax.axis('off')
    
    plt.suptitle('VGG16 Block2 Conv2 ç‰¹å¾´ãƒãƒƒãƒ—', fontsize=16)
    plt.tight_layout()
    
    output_path = os.path.join(KAGGLE_WORKING_DIR, f'feature_maps_{os.path.basename(image_path)}')
    plt.savefig(output_path, dpi=150, bbox_inches='tight')
    plt.show()

def detect_person_yolo(image_path):
    """YOLOã«ã‚ˆã‚‹äººç‰©æ¤œå‡º"""
    if not YOLO_AVAILABLE:
        print("\nâš ï¸ YOLOãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚")
        return None
    
    print(f"\nğŸ‘¤ YOLOã«ã‚ˆã‚‹äººç‰©æ¤œå‡º")
    
    # YOLOãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã‚€
    model = YOLO('yolov8n.pt')
    
    # æ¤œå‡ºå®Ÿè¡Œ
    results = model(image_path)
    
    # çµæœã‚’æç”»
    img = cv2.imread(image_path)
    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
    
    person_count = 0
    for r in results:
        boxes = r.boxes
        for box in boxes:
            # ã‚¯ãƒ©ã‚¹IDãŒ0ï¼ˆäººç‰©ï¼‰ã®å ´åˆã®ã¿
            if box.cls == 0:
                person_count += 1
                x1, y1, x2, y2 = box.xyxy[0]
                cv2.rectangle(img_rgb, (int(x1), int(y1)), (int(x2), int(y2)), (0, 255, 0), 2)
                cv2.putText(img_rgb, f'Person {box.conf[0]:.2f}', 
                           (int(x1), int(y1)-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)
    
    print(f"æ¤œå‡ºã•ã‚ŒãŸäººç‰©: {person_count}äºº")
    
    # çµæœã‚’è¡¨ç¤º
    plt.figure(figsize=(10, 8))
    plt.imshow(img_rgb)
    plt.title(f'YOLOäººç‰©æ¤œå‡ºçµæœ: {person_count}äººæ¤œå‡º')
    plt.axis('off')
    
    output_path = os.path.join(KAGGLE_WORKING_DIR, f'yolo_result_{os.path.basename(image_path)}')
    plt.savefig(output_path, dpi=150, bbox_inches='tight')
    plt.show()
    
    return person_count

def detect_person_opencv(image_path):
    """OpenCVã«ã‚ˆã‚‹äººç‰©æ¤œå‡º"""
    print(f"\nğŸ‘¤ OpenCV HOGã«ã‚ˆã‚‹äººç‰©æ¤œå‡º")
    
    # HOGæ¤œå‡ºå™¨ã‚’åˆæœŸåŒ–
    hog = cv2.HOGDescriptor()
    hog.setSVMDetector(cv2.HOGDescriptor_getDefaultPeopleDetector())
    
    # ç”»åƒã‚’èª­ã¿è¾¼ã‚€
    img = cv2.imread(image_path)
    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
    
    # äººç‰©æ¤œå‡º
    (rects, weights) = hog.detectMultiScale(img, 
                                            winStride=(4, 4),
                                            padding=(8, 8),
                                            scale=1.05)
    
    # æ¤œå‡ºçµæœã‚’æç”»
    person_count = len(rects)
    for (x, y, w, h) in rects:
        cv2.rectangle(img_rgb, (x, y), (x + w, y + h), (255, 0, 0), 2)
    
    print(f"æ¤œå‡ºã•ã‚ŒãŸäººç‰©: {person_count}äºº")
    
    # çµæœã‚’è¡¨ç¤º
    plt.figure(figsize=(10, 8))
    plt.imshow(img_rgb)
    plt.title(f'OpenCV HOGäººç‰©æ¤œå‡ºçµæœ: {person_count}äººæ¤œå‡º')
    plt.axis('off')
    
    output_path = os.path.join(KAGGLE_WORKING_DIR, f'opencv_result_{os.path.basename(image_path)}')
    plt.savefig(output_path, dpi=150, bbox_inches='tight')
    plt.show()
    
    return person_count

def create_sample_image():
    """ã‚µãƒ³ãƒ—ãƒ«ç”»åƒã‚’ä½œæˆï¼ˆãƒ‡ãƒ¢ç”¨ï¼‰"""
    print("\nğŸ¨ ã‚µãƒ³ãƒ—ãƒ«ç”»åƒã‚’ä½œæˆä¸­...")
    
    # ç°¡å˜ãªç”»åƒã‚’ä½œæˆ
    img = np.zeros((512, 512, 3), dtype=np.uint8)
    
    # å††ã‚’æç”»ï¼ˆé¡”ã®ã‚ˆã†ãªå½¢ï¼‰
    cv2.circle(img, (256, 200), 80, (255, 200, 150), -1)  # é¡”
    cv2.circle(img, (230, 180), 15, (50, 50, 50), -1)     # å·¦ç›®
    cv2.circle(img, (280, 180), 15, (50, 50, 50), -1)     # å³ç›®
    cv2.ellipse(img, (256, 220), (40, 20), 0, 0, 180, (50, 50, 50), 2)  # å£
    
    # ä½“ã‚’æç”»
    cv2.rectangle(img, (200, 280), (310, 450), (100, 100, 200), -1)
    
    # ç”»åƒã‚’ä¿å­˜
    sample_path = os.path.join(KAGGLE_WORKING_DIR, 'sample_person.jpg')
    cv2.imwrite(sample_path, img)
    
    print(f"âœ… ã‚µãƒ³ãƒ—ãƒ«ç”»åƒã‚’ä½œæˆ: {sample_path}")
    return sample_path

def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    print("\nğŸ“ Kaggleç’°å¢ƒã‚’ç¢ºèªä¸­...")
    print(f"å…¥åŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {KAGGLE_INPUT_DIR}")
    print(f"ä½œæ¥­ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {KAGGLE_WORKING_DIR}")
    
    # GPUç¢ºèª
    print(f"\nğŸ’» GPUåˆ©ç”¨å¯èƒ½: {tf.test.is_gpu_available()}")
    if tf.test.is_gpu_available():
        print(f"GPUæƒ…å ±: {tf.config.list_physical_devices('GPU')}")
    
    # ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸç”»åƒã‚’æ¢ã™
    image_files = find_input_images()
    
    # ç”»åƒãŒãªã„å ´åˆã¯ã‚µãƒ³ãƒ—ãƒ«ã‚’ä½œæˆ
    if not image_files:
        print("\nğŸ“¸ ã‚µãƒ³ãƒ—ãƒ«ç”»åƒã§å®Ÿè¡Œã—ã¾ã™")
        sample_image = create_sample_image()
        image_files = [sample_image]
    
    # å„ç”»åƒã‚’å‡¦ç†
    for image_path in image_files[:3]:  # æœ€åˆã®3æšã¾ã§å‡¦ç†
        print(f"\n{'='*60}")
        print(f"å‡¦ç†ä¸­: {image_path}")
        print('='*60)
        
        try:
            # VGG16ã«ã‚ˆã‚‹åˆ†é¡
            vgg16_classification(image_path)
            
            # ç‰¹å¾´ãƒãƒƒãƒ—ã®å¯è¦–åŒ–
            visualize_feature_maps(image_path)
            
            # äººç‰©æ¤œå‡º
            if YOLO_AVAILABLE:
                detect_person_yolo(image_path)
            detect_person_opencv(image_path)
            
        except Exception as e:
            print(f"\nâŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
            continue
    
    print("\nâœ… ã™ã¹ã¦ã®å‡¦ç†ãŒå®Œäº†ã—ã¾ã—ãŸï¼")
    print(f"çµæœã¯ {KAGGLE_WORKING_DIR} ã«ä¿å­˜ã•ã‚Œã¦ã„ã¾ã™ã€‚")

# ã‚¹ã‚¯ãƒªãƒ—ãƒˆã¨ã—ã¦å®Ÿè¡Œã•ã‚ŒãŸå ´åˆ
if __name__ == "__main__":
    main()

# Jupyter Notebookç”¨ã®ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–å®Ÿè¡Œ
print("\nğŸ’¡ ãƒ’ãƒ³ãƒˆ:")
print("å€‹åˆ¥ã®é–¢æ•°ã‚’å®Ÿè¡Œã™ã‚‹ã“ã¨ã‚‚ã§ãã¾ã™:")
print("- vgg16_classification('/path/to/image.jpg')")
print("- detect_person_opencv('/path/to/image.jpg')")
print("\nç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ã«ã¯ã€å³å´ã®ã€ŒAdd dataã€ã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„ã€‚")