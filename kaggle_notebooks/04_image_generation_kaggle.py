#!/usr/bin/env python
# -*- coding: utf-8 -*-

"""
AIç”»åƒç”Ÿæˆ - Kaggle Notebookç‰ˆ
Stable Diffusionã‚’ä½¿ã£ãŸè£½é€ æ¥­å‘ã‘ç”»åƒç”Ÿæˆ
"""

import os
import torch
from diffusers import StableDiffusionPipeline, DPMSolverMultistepScheduler
from diffusers import StableDiffusionInpaintPipeline
import numpy as np
from PIL import Image, ImageDraw, ImageFont
import matplotlib.pyplot as plt
from datetime import datetime
import json

print("ğŸ¨ AIç”»åƒç”Ÿæˆ - Kaggle Notebookç‰ˆ")
print("=" * 50)

# Kaggleãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªè¨­å®š
KAGGLE_WORKING_DIR = '/kaggle/working'

# GPUç¢ºèª
device = "cuda" if torch.cuda.is_available() else "cpu"
print(f"ğŸ’» ä½¿ç”¨ãƒ‡ãƒã‚¤ã‚¹: {device}")
if device == "cuda":
    print(f"GPUæƒ…å ±: {torch.cuda.get_device_name(0)}")

# åˆ©ç”¨å¯èƒ½ãªãƒ¢ãƒ‡ãƒ«ï¼ˆè»½é‡ç‰ˆï¼‰
MODELS = {
    "stable-diffusion": {
        "id": "CompVis/stable-diffusion-v1-4",
        "name": "Stable Diffusion v1.4",
        "description": "æ±ç”¨çš„ãªç”»åƒç”Ÿæˆ"
    },
    "anything-v3": {
        "id": "Linaqruf/anything-v3.0",
        "name": "Anything V3",
        "description": "ã‚¢ãƒ‹ãƒ¡ãƒ»ã‚¤ãƒ©ã‚¹ãƒˆé¢¨"
    }
}

class ImageGenerator:
    def __init__(self, model_name="stable-diffusion"):
        """ç”»åƒç”Ÿæˆå™¨ã‚’åˆæœŸåŒ–"""
        self.model_name = model_name
        self.model_info = MODELS[model_name]
        
        print(f"\nğŸ¨ ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã¿ä¸­: {self.model_info['name']}")
        print(f"   {self.model_info['description']}")
        print("   åˆå›ã¯æ™‚é–“ãŒã‹ã‹ã‚Šã¾ã™ï¼ˆãƒ¢ãƒ‡ãƒ«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ï¼‰...")
        
        try:
            # ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’åˆæœŸåŒ–
            self.pipe = StableDiffusionPipeline.from_pretrained(
                self.model_info['id'],
                torch_dtype=torch.float16 if device == "cuda" else torch.float32,
                safety_checker=None,
                requires_safety_checker=False
            )
            
            # ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ã‚’é«˜é€ŸåŒ–
            self.pipe.scheduler = DPMSolverMultistepScheduler.from_config(
                self.pipe.scheduler.config
            )
            
            # ãƒ‡ãƒã‚¤ã‚¹ã«ç§»å‹•
            self.pipe = self.pipe.to(device)
            
            # ãƒ¡ãƒ¢ãƒªæœ€é©åŒ–
            if device == "cuda":
                self.pipe.enable_attention_slicing()
                self.pipe.enable_vae_slicing()
            
            print("âœ… ãƒ¢ãƒ‡ãƒ«ã®æº–å‚™å®Œäº†")
            
        except Exception as e:
            print(f"âŒ ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
            self.pipe = None
    
    def generate(self, prompt, negative_prompt="", 
                 width=512, height=512, steps=20, 
                 guidance_scale=7.5, seed=None):
        """ç”»åƒã‚’ç”Ÿæˆ"""
        if self.pipe is None:
            print("âŒ ãƒ¢ãƒ‡ãƒ«ãŒèª­ã¿è¾¼ã¾ã‚Œã¦ã„ã¾ã›ã‚“")
            return None
        
        # ã‚·ãƒ¼ãƒ‰è¨­å®š
        if seed is not None:
            generator = torch.Generator(device=device).manual_seed(seed)
        else:
            generator = None
        
        print(f"\nğŸ¨ ç”»åƒç”Ÿæˆä¸­...")
        print(f"ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ: {prompt}")
        print(f"ã‚µã‚¤ã‚º: {width}x{height}, ã‚¹ãƒ†ãƒƒãƒ—: {steps}")
        
        try:
            # ç”»åƒç”Ÿæˆ
            with torch.autocast(device):
                result = self.pipe(
                    prompt=prompt,
                    negative_prompt=negative_prompt,
                    width=width,
                    height=height,
                    num_inference_steps=steps,
                    guidance_scale=guidance_scale,
                    generator=generator
                )
            
            image = result.images[0]
            
            # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’è¿½åŠ 
            metadata = {
                "prompt": prompt,
                "negative_prompt": negative_prompt,
                "model": self.model_name,
                "size": f"{width}x{height}",
                "steps": steps,
                "guidance_scale": guidance_scale,
                "seed": seed,
                "timestamp": datetime.now().isoformat()
            }
            
            return image, metadata
            
        except Exception as e:
            print(f"âŒ ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
            return None, None

def create_manufacturing_prompts():
    """è£½é€ æ¥­å‘ã‘ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®ä¾‹"""
    prompts = {
        "å“è³ªæ¤œæŸ»": {
            "prompt": "quality inspection process in modern factory, worker examining metal parts with magnifying glass, bright LED lighting, clean environment, professional photography",
            "negative": "blurry, dark, dirty, unsafe"
        },
        "è‡ªå‹•åŒ–ãƒ©ã‚¤ãƒ³": {
            "prompt": "automated production line, industrial robots assembling products, blue and white color scheme, high tech factory, wide angle shot",
            "negative": "old, broken, rusty, manual labor"
        },
        "ç²¾å¯†éƒ¨å“": {
            "prompt": "precision machined metal components, gear mechanisms, technical photography, macro lens, perfect surface finish, engineering drawing style",
            "negative": "rough, damaged, dirty, low quality"
        },
        "ã‚¯ãƒªãƒ¼ãƒ³ãƒ«ãƒ¼ãƒ ": {
            "prompt": "semiconductor cleanroom facility, workers in white protective suits, advanced equipment, sterile environment, futuristic atmosphere",
            "negative": "contaminated, dirty, casual clothing"
        },
        "æº¶æ¥ä½œæ¥­": {
            "prompt": "professional welding operation, bright sparks, safety equipment, industrial setting, dramatic lighting, high speed photography",
            "negative": "unsafe, amateur, poor quality weld"
        }
    }
    return prompts

def generate_prompt_variations(base_prompt, variations=3):
    """ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®ãƒãƒªã‚¨ãƒ¼ã‚·ãƒ§ãƒ³ã‚’ç”Ÿæˆ"""
    styles = [
        "photorealistic, 8k, highly detailed",
        "technical drawing style, blueprint, precise",
        "professional photography, studio lighting",
        "cinematic, dramatic lighting, wide angle",
        "macro photography, extreme close-up, sharp focus"
    ]
    
    varied_prompts = []
    for i in range(variations):
        style = styles[i % len(styles)]
        varied_prompt = f"{base_prompt}, {style}"
        varied_prompts.append(varied_prompt)
    
    return varied_prompts

def create_comparison_grid(images, prompts, save_path=None):
    """è¤‡æ•°ã®ç”Ÿæˆç”»åƒã‚’æ¯”è¼ƒè¡¨ç¤º"""
    n_images = len(images)
    cols = min(3, n_images)
    rows = (n_images + cols - 1) // cols
    
    fig, axes = plt.subplots(rows, cols, figsize=(cols * 4, rows * 4))
    
    if n_images == 1:
        axes = [axes]
    else:
        axes = axes.flatten() if rows > 1 else axes
    
    for i, (img, prompt) in enumerate(zip(images, prompts)):
        if i < len(axes):
            axes[i].imshow(img)
            axes[i].set_title(prompt[:50] + "..." if len(prompt) > 50 else prompt, 
                            fontsize=10, wrap=True)
            axes[i].axis('off')
    
    # ä½™åˆ†ãªè»¸ã‚’éè¡¨ç¤º
    for i in range(len(images), len(axes)):
        axes[i].axis('off')
    
    plt.tight_layout()
    
    if save_path:
        plt.savefig(save_path, dpi=150, bbox_inches='tight')
    
    plt.show()
    return fig

def batch_generate(generator, prompt_dict, save_results=True):
    """è¤‡æ•°ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã§ä¸€æ‹¬ç”Ÿæˆ"""
    results = []
    images = []
    prompts_used = []
    
    for name, prompt_info in prompt_dict.items():
        print(f"\nğŸ“¸ ç”Ÿæˆä¸­: {name}")
        
        image, metadata = generator.generate(
            prompt=prompt_info['prompt'],
            negative_prompt=prompt_info['negative'],
            width=512,
            height=512,
            steps=20
        )
        
        if image:
            # ä¿å­˜
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"{name.replace(' ', '_')}_{timestamp}.png"
            filepath = os.path.join(KAGGLE_WORKING_DIR, filename)
            image.save(filepath)
            
            results.append({
                'name': name,
                'filename': filename,
                'metadata': metadata
            })
            
            images.append(image)
            prompts_used.append(name)
            
            print(f"âœ… ä¿å­˜: {filename}")
    
    # æ¯”è¼ƒã‚°ãƒªãƒƒãƒ‰ã‚’ä½œæˆ
    if images:
        grid_path = os.path.join(KAGGLE_WORKING_DIR, "comparison_grid.png")
        create_comparison_grid(images, prompts_used, grid_path)
    
    # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜
    if save_results and results:
        meta_path = os.path.join(KAGGLE_WORKING_DIR, "generation_metadata.json")
        with open(meta_path, 'w', encoding='utf-8') as f:
            json.dump(results, f, ensure_ascii=False, indent=2)
        print(f"\nğŸ“„ ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ä¿å­˜: {meta_path}")
    
    return results

def create_inpainting_demo():
    """ã‚¤ãƒ³ãƒšã‚¤ãƒ³ãƒ†ã‚£ãƒ³ã‚°ï¼ˆç”»åƒä¿®æ­£ï¼‰ã®ãƒ‡ãƒ¢"""
    print("\nğŸ”§ ç”»åƒä¿®æ­£ãƒ‡ãƒ¢")
    
    # ã‚µãƒ³ãƒ—ãƒ«ç”»åƒã¨ãƒã‚¹ã‚¯ã‚’ä½œæˆ
    base_image = Image.new('RGB', (512, 512), color='lightgray')
    draw = ImageDraw.Draw(base_image)
    
    # é‡‘å±éƒ¨å“ã®ã‚ˆã†ãªå½¢ã‚’æç”»
    draw.rectangle([100, 100, 400, 400], fill='silver')
    draw.ellipse([200, 200, 300, 300], fill='darkgray')
    
    # å‚·ã‚’è¿½åŠ 
    draw.line([(150, 150), (350, 350)], fill='black', width=5)
    draw.line([(150, 350), (350, 150)], fill='black', width=5)
    
    # ãƒã‚¹ã‚¯ï¼ˆä¿®æ­£ã—ãŸã„éƒ¨åˆ†ï¼‰
    mask = Image.new('L', (512, 512), color='white')
    mask_draw = ImageDraw.Draw(mask)
    mask_draw.line([(150, 150), (350, 350)], fill='black', width=20)
    mask_draw.line([(150, 350), (350, 150)], fill='black', width=20)
    
    # è¡¨ç¤º
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 5))
    ax1.imshow(base_image)
    ax1.set_title("å…ƒç”»åƒï¼ˆå‚·ã‚ã‚Šï¼‰")
    ax1.axis('off')
    
    ax2.imshow(mask, cmap='gray')
    ax2.set_title("ä¿®æ­£ãƒã‚¹ã‚¯ï¼ˆé»’ã„éƒ¨åˆ†ã‚’ä¿®æ­£ï¼‰")
    ax2.axis('off')
    
    plt.tight_layout()
    plt.show()
    
    # ãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ä¿å­˜
    base_path = os.path.join(KAGGLE_WORKING_DIR, "sample_damaged.png")
    mask_path = os.path.join(KAGGLE_WORKING_DIR, "sample_mask.png")
    base_image.save(base_path)
    mask.save(mask_path)
    
    print(f"âœ… ã‚µãƒ³ãƒ—ãƒ«ç”»åƒã‚’ä¿å­˜:")
    print(f"  - å…ƒç”»åƒ: {base_path}")
    print(f"  - ãƒã‚¹ã‚¯: {mask_path}")
    
    return base_path, mask_path

def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    print("\nğŸš€ AIç”»åƒç”Ÿæˆã‚’é–‹å§‹")
    
    # ç”»åƒç”Ÿæˆå™¨ã‚’åˆæœŸåŒ–
    generator = ImageGenerator("stable-diffusion")
    
    if generator.pipe is None:
        print("âš ï¸ ãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ")
        return
    
    # è£½é€ æ¥­å‘ã‘ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’å–å¾—
    prompts = create_manufacturing_prompts()
    
    # ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ãƒ¡ãƒ‹ãƒ¥ãƒ¼
    print("\nğŸ“‹ å®Ÿè¡Œã‚ªãƒ—ã‚·ãƒ§ãƒ³:")
    print("1. è£½é€ æ¥­ã‚µãƒ³ãƒ—ãƒ«ã‚’ä¸€æ‹¬ç”Ÿæˆ")
    print("2. ã‚«ã‚¹ã‚¿ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã§ç”Ÿæˆ")
    print("3. ç”»åƒä¿®æ­£ãƒ‡ãƒ¢")
    
    # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§1ã‚’å®Ÿè¡Œ
    choice = "1"
    
    if choice == "1":
        # ã‚µãƒ³ãƒ—ãƒ«ã‚’ä¸€æ‹¬ç”Ÿæˆ
        print("\nğŸ­ è£½é€ æ¥­ã‚µãƒ³ãƒ—ãƒ«ã‚’ç”Ÿæˆã—ã¾ã™")
        results = batch_generate(generator, prompts)
        
        print(f"\nâœ… {len(results)}æšã®ç”»åƒã‚’ç”Ÿæˆã—ã¾ã—ãŸ")
        print(f"ä¿å­˜å…ˆ: {KAGGLE_WORKING_DIR}")
        
    elif choice == "2":
        # ã‚«ã‚¹ã‚¿ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
        custom_prompt = "modern factory interior with advanced robotics"
        print(f"\nğŸ¨ ã‚«ã‚¹ã‚¿ãƒ ç”Ÿæˆ: {custom_prompt}")
        
        image, metadata = generator.generate(
            prompt=custom_prompt,
            negative_prompt="old, dirty, dangerous",
            width=512,
            height=512,
            steps=30
        )
        
        if image:
            save_path = os.path.join(KAGGLE_WORKING_DIR, "custom_generation.png")
            image.save(save_path)
            print(f"âœ… ä¿å­˜: {save_path}")
            
            plt.figure(figsize=(8, 8))
            plt.imshow(image)
            plt.title(custom_prompt)
            plt.axis('off')
            plt.show()
    
    elif choice == "3":
        # ç”»åƒä¿®æ­£ãƒ‡ãƒ¢
        create_inpainting_demo()
    
    print("\nğŸ“ æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—:")
    print("- ç”Ÿæˆã—ãŸç”»åƒã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¦ä½¿ç”¨")
    print("- ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’èª¿æ•´ã—ã¦ã‚ˆã‚Šè‰¯ã„çµæœã‚’å¾—ã‚‹")
    print("- seedå€¤ã‚’å›ºå®šã—ã¦åŒã˜ç”»åƒã‚’å†ç¾")

# ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–é–¢æ•°
def quick_generate(prompt, negative="low quality, blurry", size=512, steps=20):
    """ç°¡å˜ãªç”»åƒç”Ÿæˆé–¢æ•°"""
    generator = ImageGenerator("stable-diffusion")
    
    if generator.pipe:
        image, metadata = generator.generate(
            prompt=prompt,
            negative_prompt=negative,
            width=size,
            height=size,
            steps=steps
        )
        
        if image:
            # è¡¨ç¤º
            plt.figure(figsize=(8, 8))
            plt.imshow(image)
            plt.title(prompt[:80] + "..." if len(prompt) > 80 else prompt)
            plt.axis('off')
            plt.show()
            
            # ä¿å­˜
            filename = f"generated_{datetime.now().strftime('%Y%m%d_%H%M%S')}.png"
            filepath = os.path.join(KAGGLE_WORKING_DIR, filename)
            image.save(filepath)
            print(f"ğŸ’¾ ä¿å­˜: {filepath}")
            
            return image
    
    return None

# ã‚¹ã‚¯ãƒªãƒ—ãƒˆå®Ÿè¡Œ
if __name__ == "__main__":
    main()

# ä½¿ç”¨æ–¹æ³•
print("\nğŸ’¡ ã‚¯ã‚¤ãƒƒã‚¯ç”Ÿæˆ:")
print('quick_generate("industrial robot in action")')
print('quick_generate("precision mechanical parts", negative="damaged, dirty", steps=30)')