# ç¬¬2æ™‚ï¼šãƒ‡ã‚£ãƒ¼ãƒ—ãƒ©ãƒ¼ãƒ‹ãƒ³ã‚°ã§ç‰©ä½“èªè­˜ã‚’ä½“é¨“ã—ã‚ˆã†

## ðŸŽ¯ ä»Šæ—¥ã®ç›®æ¨™
AIãŒã©ã†ã‚„ã£ã¦ç”»åƒã‚’èªè­˜ã™ã‚‹ã®ã‹ç†è§£ã—ã¦ã€å®Ÿéš›ã«ä½“é¨“ã™ã‚‹ï¼

---

## ðŸ“ æ©Ÿæ¢°å­¦ç¿’ã¨ãƒ‡ã‚£ãƒ¼ãƒ—ãƒ©ãƒ¼ãƒ‹ãƒ³ã‚°

### äººé–“ã®å­¦ç¿’ vs æ©Ÿæ¢°ã®å­¦ç¿’

**äººé–“ã®å ´åˆ**
1. çŒ«ã‚’è¦‹ã‚‹ â†’ ã€Œã“ã‚Œã¯çŒ«ã ã€ã¨æ•™ã‚ã‚‹
2. ä½•åº¦ã‚‚è¦‹ã‚‹ â†’ ç‰¹å¾´ã‚’è¦šãˆã‚‹ï¼ˆè€³ã®å½¢ã€ãƒ’ã‚²ã€é³´ãå£°ï¼‰
3. æ–°ã—ã„çŒ«ã‚’è¦‹ã‚‹ â†’ ã€Œã“ã‚Œã‚‚çŒ«ã ï¼ã€ã¨åˆ†ã‹ã‚‹

**æ©Ÿæ¢°ã®å ´åˆ**
1. ãŸãã•ã‚“ã®çŒ«ã®ç”»åƒã‚’è¦‹ã›ã‚‹ï¼ˆãƒ‡ãƒ¼ã‚¿ï¼‰
2. ç‰¹å¾´ã‚’è‡ªå‹•ã§è¦‹ã¤ã‘ã‚‹ï¼ˆå­¦ç¿’ï¼‰
3. æ–°ã—ã„ç”»åƒã‚’åˆ¤å®šã™ã‚‹ï¼ˆäºˆæ¸¬ï¼‰

### ãƒ‡ã‚£ãƒ¼ãƒ—ãƒ©ãƒ¼ãƒ‹ãƒ³ã‚°ã®ä»•çµ„ã¿

```
å…¥åŠ›ï¼ˆç”»åƒï¼‰ â†’ ç‰¹å¾´æŠ½å‡º â†’ ãƒ‘ã‚¿ãƒ¼ãƒ³èªè­˜ â†’ çµæžœï¼ˆçŒ«/çŠ¬ï¼‰
```

ç”»åƒã¯ã€Œãƒ”ã‚¯ã‚»ãƒ«ï¼ˆç‚¹ï¼‰ã®é›†ã¾ã‚Šã€ã¨ã—ã¦èªè­˜ã•ã‚Œã¾ã™ï¼š
- å„ãƒ”ã‚¯ã‚»ãƒ«ã«ã¯è‰²ã®æƒ…å ±ï¼ˆRGBï¼‰
- AIã¯ãƒ”ã‚¯ã‚»ãƒ«ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã‹ã‚‰ç‰¹å¾´ã‚’å­¦ç¿’

---

## ðŸš€ Google Colabã‚’ä½¿ã£ã¦ã¿ã‚ˆã†

### ã‚¹ãƒ†ãƒƒãƒ—1ï¼šGoogle Colabã«ã‚¢ã‚¯ã‚»ã‚¹

1. **Google Colabã‚’é–‹ã**
   - https://colab.research.google.com/
   - Googleã‚¢ã‚«ã‚¦ãƒ³ãƒˆã§ãƒ­ã‚°ã‚¤ãƒ³

2. **æ–°ã—ã„ãƒŽãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã‚’ä½œæˆ**
   - ã€Œãƒ•ã‚¡ã‚¤ãƒ«ã€â†’ã€Œæ–°ã—ã„ãƒŽãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã€
   - åå‰ã‚’å¤‰æ›´ï¼š`ç‰©ä½“èªè­˜ä½“é¨“.ipynb`

### ã‚¹ãƒ†ãƒƒãƒ—2ï¼šåŸºæœ¬æ“ä½œã‚’è¦šãˆã‚‹

**ã‚»ãƒ«**ï¼šã‚³ãƒ¼ãƒ‰ã‚’æ›¸ãå ´æ‰€
- `+ ã‚³ãƒ¼ãƒ‰`ï¼šæ–°ã—ã„ã‚³ãƒ¼ãƒ‰ã‚»ãƒ«ã‚’è¿½åŠ 
- `+ ãƒ†ã‚­ã‚¹ãƒˆ`ï¼šèª¬æ˜Žæ–‡ã‚’è¿½åŠ 
- `Shift + Enter`ï¼šã‚»ãƒ«ã‚’å®Ÿè¡Œ

### ç°¡å˜ãªè¨ˆç®—ã‚’ã—ã¦ã¿ã‚ˆã†

```python
# ã“ã‚Œã¯ã‚³ãƒ¡ãƒ³ãƒˆï¼ˆå®Ÿè¡Œã•ã‚Œãªã„èª¬æ˜Žæ–‡ï¼‰
print("ã“ã‚“ã«ã¡ã¯ã€AIï¼")

# è¨ˆç®—ã‚‚ã§ãã‚‹
2 + 3
```

å®Ÿè¡Œã™ã‚‹ã¨ï¼š
```
ã“ã‚“ã«ã¡ã¯ã€AIï¼
5
```

---

## ðŸ–¼ï¸ äº‹å‰å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã§ç”»åƒèªè­˜

### VGG16ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ã£ãŸç”»åƒèªè­˜

**VGG16ã¨ã¯ï¼Ÿ**
- 100ä¸‡æžšä»¥ä¸Šã®ç”»åƒã§å­¦ç¿’æ¸ˆã¿
- 1000ç¨®é¡žã®ç‰©ä½“ã‚’èªè­˜ã§ãã‚‹
- ã™ãã«ä½¿ãˆã‚‹å„ªç§€ãªãƒ¢ãƒ‡ãƒ«

### ã‚¹ãƒ†ãƒƒãƒ—1ï¼šå¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«

```python
# ç”»åƒå‡¦ç†ã¨æ©Ÿæ¢°å­¦ç¿’ã®ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
!pip install tensorflow pillow matplotlib
```

### ã‚¹ãƒ†ãƒƒãƒ—2ï¼šãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ

```python
# å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’èª­ã¿è¾¼ã‚€
import tensorflow as tf
from tensorflow.keras.applications import VGG16
from tensorflow.keras.preprocessing import image
from tensorflow.keras.applications.vgg16 import preprocess_input, decode_predictions
import numpy as np
import matplotlib.pyplot as plt
from PIL import Image
```

### ã‚¹ãƒ†ãƒƒãƒ—3ï¼šãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã‚€

```python
# VGG16ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã‚€ï¼ˆåˆå›žã¯å°‘ã—æ™‚é–“ãŒã‹ã‹ã‚Šã¾ã™ï¼‰
print("ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã‚“ã§ã„ã¾ã™...")
model = VGG16(weights='imagenet')
print("æº–å‚™å®Œäº†ï¼")
```

### ã‚¹ãƒ†ãƒƒãƒ—4ï¼šç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦èªè­˜

```python
# ç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã™ã‚‹æ©Ÿèƒ½
from google.colab import files

print("èªè­˜ã—ãŸã„ç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„")
uploaded = files.upload()

# ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸç”»åƒã®ãƒ•ã‚¡ã‚¤ãƒ«åã‚’å–å¾—
filename = list(uploaded.keys())[0]
print(f"ç”»åƒ '{filename}' ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¾ã—ãŸ")
```

### ã‚¹ãƒ†ãƒƒãƒ—5ï¼šç”»åƒã‚’å‰å‡¦ç†ã—ã¦äºˆæ¸¬

```python
# ç”»åƒã‚’èª­ã¿è¾¼ã‚“ã§å‰å‡¦ç†
img = image.load_img(filename, target_size=(224, 224))
img_array = image.img_to_array(img)
img_array = np.expand_dims(img_array, axis=0)
img_array = preprocess_input(img_array)

# äºˆæ¸¬å®Ÿè¡Œ
print("AIãŒç”»åƒã‚’åˆ†æžä¸­...")
predictions = model.predict(img_array)

# çµæžœã‚’è§£é‡ˆï¼ˆä¸Šä½3ã¤ï¼‰
results = decode_predictions(predictions, top=3)[0]

# çµæžœã‚’è¡¨ç¤º
print("\n=== èªè­˜çµæžœ ===")
for i, (imagenet_id, label, score) in enumerate(results):
    print(f"{i+1}ä½: {label} ({score*100:.1f}%)")
```

### ã‚¹ãƒ†ãƒƒãƒ—6ï¼šçµæžœã‚’è¦–è¦šçš„ã«è¡¨ç¤º

```python
# ç”»åƒã¨çµæžœã‚’ä¸¦ã¹ã¦è¡¨ç¤º
plt.figure(figsize=(10, 5))

# å·¦å´ã«ç”»åƒ
plt.subplot(1, 2, 1)
plt.imshow(img)
plt.title('å…¥åŠ›ç”»åƒ')
plt.axis('off')

# å³å´ã«çµæžœã®ã‚°ãƒ©ãƒ•
plt.subplot(1, 2, 2)
labels = [r[1] for r in results]
scores = [r[2] for r in results]
plt.barh(labels, scores)
plt.xlabel('ç¢ºçŽ‡')
plt.title('èªè­˜çµæžœ Top3')
plt.xlim(0, 1)

plt.tight_layout()
plt.show()
```

---

## ðŸ” ç‰¹å¾´ãƒžãƒƒãƒ—ã‚’è¦‹ã¦ã¿ã‚ˆã†

AIãŒç”»åƒã®ã©ã“ã«æ³¨ç›®ã—ã¦ã„ã‚‹ã‹å¯è¦–åŒ–ã—ã¦ã¿ã¾ã—ã‚‡ã†ã€‚

```python
# ãƒ¢ãƒ‡ãƒ«ã®ä¸­é–“å±¤ã‚’å–å¾—
from tensorflow.keras.models import Model

# æœ€åˆã®ç•³ã¿è¾¼ã¿å±¤ã®å‡ºåŠ›ã‚’å–å¾—
layer_outputs = [layer.output for layer in model.layers[1:6]]
activation_model = Model(inputs=model.input, outputs=layer_outputs)

# ç‰¹å¾´ãƒžãƒƒãƒ—ã‚’è¨ˆç®—
activations = activation_model.predict(img_array)

# æœ€åˆã®å±¤ã®ç‰¹å¾´ãƒžãƒƒãƒ—ã‚’è¡¨ç¤º
first_layer_activation = activations[0]
plt.figure(figsize=(15, 8))

# 8å€‹ã®ç‰¹å¾´ãƒžãƒƒãƒ—ã‚’è¡¨ç¤º
for i in range(8):
    plt.subplot(2, 4, i + 1)
    plt.imshow(first_layer_activation[0, :, :, i], cmap='viridis')
    plt.title(f'ç‰¹å¾´ãƒžãƒƒãƒ— {i+1}')
    plt.axis('off')

plt.suptitle('AIãŒè¦‹ã¦ã„ã‚‹ç‰¹å¾´ï¼ˆæœ€åˆã®å±¤ï¼‰')
plt.show()
```

---

## ðŸŽ® ç·´ç¿’å•é¡Œ

### èª²é¡Œ1ï¼šã„ã‚ã„ã‚ãªç”»åƒã§è©¦ã—ã¦ã¿ã‚ˆã†

ä»¥ä¸‹ã®ç”»åƒã§èªè­˜ç²¾åº¦ã‚’ç¢ºèªï¼š
1. å·¥å…·ï¼ˆãƒ‰ãƒ©ã‚¤ãƒãƒ¼ã€ãƒ¬ãƒ³ãƒãªã©ï¼‰
2. é‡‘å±žéƒ¨å“
3. è‡ªåˆ†ã®ã‚¹ãƒžãƒ¼ãƒˆãƒ•ã‚©ãƒ³ã§æ’®ã£ãŸå†™çœŸ

### èª²é¡Œ2ï¼šèªè­˜çµæžœã‚’ã¾ã¨ã‚ã‚ˆã†

| ç”»åƒã®å†…å®¹ | 1ä½ã®äºˆæ¸¬ | ç¢ºçŽ‡ | æ­£ã—ã‹ã£ãŸï¼Ÿ |
|-----------|----------|------|-------------|
| ä¾‹ï¼šãƒ‰ãƒ©ã‚¤ãƒãƒ¼ | screwdriver | 92.3% | â—‹ |
| | | | |
| | | | |

### èª²é¡Œ3ï¼šè€ƒå¯Ÿ

1. ã©ã‚“ãªç”»åƒãŒæ­£ã—ãèªè­˜ã•ã‚Œã‚„ã™ã„ï¼Ÿ
2. èªè­˜ã«å¤±æ•—ã—ãŸç”»åƒã®å…±é€šç‚¹ã¯ï¼Ÿ
3. å·¥å ´ã§ä½¿ã†ã«ã¯ã©ã‚“ãªæ”¹å–„ãŒå¿…è¦ï¼Ÿ

---

## ðŸ’¡ ç™ºå±•èª²é¡Œï¼šäººç‰©èªè­˜ã‚’è¿½åŠ ã—ã¦ã¿ã‚ˆã†

```python
# 1. åŸºæœ¬ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ç¢ºèª
import cv2
import numpy as np
import matplotlib.pyplot as plt
from ultralytics import YOLO

# 2. VGG16é–¢é€£ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ  
from tensorflow.keras.applications import VGG16
from tensorflow.keras.preprocessing import image
from tensorflow.keras.applications.vgg16 import preprocess_input, decode_predictions

print("âœ… ã™ã¹ã¦ã®ãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒæ­£å¸¸ã«ã‚¤ãƒ³ãƒãƒ¼ãƒˆã•ã‚Œã¾ã—ãŸ")
```


```python
# é–¢æ•°å®šç¾©
def yolo_person_detection(image_path):
    """
    YOLOv8ã‚’ä½¿ã£ãŸäººç‰©æ¤œå‡º
    """
    print("=== YOLOäººç‰©æ¤œå‡º ===")
    
    # YOLOv8ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰ï¼ˆåˆå›žã¯è‡ªå‹•ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ï¼‰
    model = YOLO('yolov8n.pt')  # nanoç‰ˆï¼ˆè»½é‡ï¼‰
    
    # ç”»åƒã‚’èª­ã¿è¾¼ã¿
    image = cv2.imread(image_path)
    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
    
    # æŽ¨è«–å®Ÿè¡Œ
    results = model(image_path)
    
    # äººç‰©ï¼ˆã‚¯ãƒ©ã‚¹0ï¼‰ã®ã¿ã‚’æŠ½å‡º
    person_detections = []
    for r in results:
        boxes = r.boxes
        if boxes is not None:
            for box in boxes:
                class_id = int(box.cls[0])
                confidence = float(box.conf[0])
                
                # ã‚¯ãƒ©ã‚¹0ãŒäººç‰©
                if class_id == 0 and confidence > 0.5:
                    x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()
                    person_detections.append({
                        'bbox': (int(x1), int(y1), int(x2), int(y2)),
                        'confidence': confidence
                    })
    
    # çµæžœã‚’æç”»
    result_image = image_rgb.copy()
    for detection in person_detections:
        x1, y1, x2, y2 = detection['bbox']
        confidence = detection['confidence']
        
        # ãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹ã‚’æç”»
        cv2.rectangle(result_image, (x1, y1), (x2, y2), (0, 255, 0), 2)
        cv2.putText(result_image, f'Person: {confidence:.2f}', 
                   (x1, y1-10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)
    
    print(f"æ¤œå‡ºã•ã‚ŒãŸäººç‰©æ•°: {len(person_detections)}")
    for i, detection in enumerate(person_detections):
        print(f"äººç‰©{i+1}: ä¿¡é ¼åº¦ {detection['confidence']:.3f}")
    
    return result_image, person_detections

def opencv_person_detection(image_path):
    """
    OpenCVã®HOG + SVMã‚’ä½¿ã£ãŸäººç‰©æ¤œå‡º
    """
    print("\n=== OpenCVäººç‰©æ¤œå‡º ===")
    
    # ç”»åƒã‚’èª­ã¿è¾¼ã¿
    image = cv2.imread(image_path)
    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
    
    # HOGè¨˜è¿°å­ã‚’åˆæœŸåŒ–
    hog = cv2.HOGDescriptor()
    hog.setSVMDetector(cv2.HOGDescriptor_getDefaultPeopleDetector())
    
    # äººç‰©æ¤œå‡ºã‚’å®Ÿè¡Œ
    boxes, weights = hog.detectMultiScale(
        image_rgb,
        winStride=(8, 8),
        padding=(32, 32),
        scale=1.05,
        useMeanshiftGrouping=False
    )
    
    # çµæžœã‚’æç”»
    result_image = image_rgb.copy()
    person_detections = []
    
    for i, (x, y, w, h) in enumerate(boxes):
        confidence = weights[i][0] if len(weights) > i else 0.5
        
        # ãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹ã‚’æç”»
        cv2.rectangle(result_image, (x, y), (x + w, y + h), (255, 0, 0), 2)
        cv2.putText(result_image, f'Person: {confidence:.2f}', 
                   (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 0, 0), 2)
        
        person_detections.append({
            'bbox': (x, y, x + w, y + h),
            'confidence': confidence
        })
    
    print(f"æ¤œå‡ºã•ã‚ŒãŸäººç‰©æ•°: {len(person_detections)}")
    for i, detection in enumerate(person_detections):
        print(f"äººç‰©{i+1}: ä¿¡é ¼åº¦ {detection['confidence']:.3f}")
    
    return result_image, person_detections

def opencv_person_detection(image_path):
    """
    OpenCVã®HOG + SVMã‚’ä½¿ã£ãŸäººç‰©æ¤œå‡ºï¼ˆä¿®æ­£ç‰ˆï¼‰
    """
    print("\n=== OpenCVäººç‰©æ¤œå‡º ===")
    
    # ç”»åƒã‚’èª­ã¿è¾¼ã¿
    image = cv2.imread(image_path)
    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
    
    # HOGè¨˜è¿°å­ã‚’åˆæœŸåŒ–
    hog = cv2.HOGDescriptor()
    hog.setSVMDetector(cv2.HOGDescriptor_getDefaultPeopleDetector())
    
    # äººç‰©æ¤œå‡ºã‚’å®Ÿè¡Œ
    boxes, weights = hog.detectMultiScale(
        image_rgb,
        winStride=(8, 8),
        padding=(32, 32),
        scale=1.05,
        useMeanshiftGrouping=False
    )
    
    # çµæžœã‚’æç”»
    result_image = image_rgb.copy()
    person_detections = []
    
    for i, (x, y, w, h) in enumerate(boxes):
        # weightsã®å½¢çŠ¶ã‚’ç¢ºèªã—ã¦é©åˆ‡ã«å‡¦ç†
        if len(weights) > 0:
            if weights.ndim > 1 and weights.shape[1] > 0:
                confidence = weights[i][0] if i < len(weights) else 0.5
            else:
                confidence = weights[i] if i < len(weights) else 0.5
        else:
            confidence = 0.5
        
        # ãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹ã‚’æç”»
        cv2.rectangle(result_image, (x, y), (x + w, y + h), (255, 0, 0), 2)
        cv2.putText(result_image, f'Person: {confidence:.2f}', 
                   (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 0, 0), 2)
        
        person_detections.append({
            'bbox': (x, y, x + w, y + h),
            'confidence': float(confidence)
        })
    
    print(f"æ¤œå‡ºã•ã‚ŒãŸäººç‰©æ•°: {len(person_detections)}")
    for i, detection in enumerate(person_detections):
        print(f"äººç‰©{i+1}: ä¿¡é ¼åº¦ {detection['confidence']:.3f}")
    
    return result_image, person_detections

# ä¿®æ­£ç‰ˆã‚’å®šç¾©ã—ã¾ã—ãŸ
print("âœ… OpenCVäººç‰©æ¤œå‡ºé–¢æ•°ã‚’ä¿®æ­£ã—ã¾ã—ãŸ")

def detect_all_methods(image_path):
    """
    ã™ã¹ã¦ã®æ¤œå‡ºæ–¹æ³•ã‚’å®Ÿè¡Œã—ã¦æ¯”è¼ƒ
    """
    print("ç”»åƒã®äººç‰©ãƒ»é¡”æ¤œå‡ºã‚’é–‹å§‹...")
    print(f"å¯¾è±¡ç”»åƒ: {image_path}")
    
    # å„æ‰‹æ³•ã§æ¤œå‡ºå®Ÿè¡Œ
    yolo_result, yolo_detections = yolo_person_detection(image_path)
    opencv_result, opencv_detections = opencv_person_detection(image_path)
    face_result, face_detections = opencv_face_detection(image_path)
    
    # çµæžœã‚’å¯è¦–åŒ–
    plt.figure(figsize=(15, 5))
    
    plt.subplot(1, 3, 1)
    plt.imshow(yolo_result)
    plt.title(f'YOLOæ¤œå‡º ({len(yolo_detections)}äºº)')
    plt.axis('off')
    
    plt.subplot(1, 3, 2)
    plt.imshow(opencv_result)
    plt.title(f'OpenCV HOGæ¤œå‡º ({len(opencv_detections)}äºº)')
    plt.axis('off')
    
    plt.subplot(1, 3, 3)
    plt.imshow(face_result)
    plt.title(f'OpenCVé¡”æ¤œå‡º ({len(face_detections)}é¡”)')
    plt.axis('off')
    
    plt.tight_layout()
    plt.show()
    
    # ç·åˆçµæžœ
    print("\n=== ç·åˆçµæžœ ===")
    print(f"YOLO: {len(yolo_detections)}äººæ¤œå‡º")
    print(f"OpenCV HOG: {len(opencv_detections)}äººæ¤œå‡º") 
    print(f"OpenCV é¡”æ¤œå‡º: {len(face_detections)}é¡”æ¤œå‡º")
    
    return {
        'yolo': yolo_detections,
        'opencv_hog': opencv_detections,
        'face': face_detections
    }

# é–¢æ•°å®šç¾©ãŒå®Œäº†ã—ã¾ã—ãŸ
print("âœ… äººç‰©æ¤œå‡ºé–¢æ•°ãŒå®šç¾©ã•ã‚Œã¾ã—ãŸ")
```


```python
# VGG16ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰
model = VGG16(weights='imagenet')

# Google Colabã§ã®ç”»åƒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰æ©Ÿèƒ½ã¨çµ±åˆ
from google.colab import files

print("èªè­˜ã—ãŸã„ç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„")
uploaded = files.upload()

# ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸç”»åƒã®ãƒ•ã‚¡ã‚¤ãƒ«åã‚’å–å¾—
filename = list(uploaded.keys())[0]
print(f"ç”»åƒ '{filename}' ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¾ã—ãŸ")

# VGG16ã«ã‚ˆã‚‹åˆ†é¡žï¼ˆæ—¢å­˜ã®ã‚³ãƒ¼ãƒ‰ï¼‰
print("\n" + "="*50)
print("VGG16ã«ã‚ˆã‚‹ç”»åƒåˆ†é¡ž")
print("="*50)

# ç”»åƒã‚’èª­ã¿è¾¼ã‚“ã§å‰å‡¦ç†
img = image.load_img(filename, target_size=(224, 224))
img_array = image.img_to_array(img)
img_array = np.expand_dims(img_array, axis=0)
img_array = preprocess_input(img_array)

# äºˆæ¸¬å®Ÿè¡Œ
print("AIãŒç”»åƒã‚’åˆ†æžä¸­...")
predictions = model.predict(img_array)

# çµæžœã‚’è§£é‡ˆï¼ˆä¸Šä½3ã¤ï¼‰
results = decode_predictions(predictions, top=3)[0]

# çµæžœã‚’è¡¨ç¤º
print("\n=== VGG16èªè­˜çµæžœ ===")
for i, (imagenet_id, label, score) in enumerate(results):
    print(f"{i+1}ä½: {label} ({score*100:.1f}%)")

# äººç‰©ãƒ»é¡”æ¤œå‡ºã®å®Ÿè¡Œ
print("\n" + "="*50)
print("äººç‰©ãƒ»é¡”æ¤œå‡ºã®é–‹å§‹")
print("="*50)

# ã™ã¹ã¦ã®æ¤œå‡ºæ‰‹æ³•ã‚’å®Ÿè¡Œ
detection_results = detect_all_methods(filename)
```

---

## ðŸ¤” ã‚ˆãã‚ã‚‹è³ªå•

**Q: ãªãœ224Ã—224ã®ã‚µã‚¤ã‚ºã«ã™ã‚‹ã®ï¼Ÿ**
A: VGG16ãƒ¢ãƒ‡ãƒ«ãŒãã®å¤§ãã•ã§å­¦ç¿’ã•ã‚ŒãŸã‹ã‚‰ã€‚ãƒ¢ãƒ‡ãƒ«ã”ã¨ã«æ±ºã¾ã£ãŸã‚µã‚¤ã‚ºãŒã‚ã‚Šã¾ã™ã€‚

**Q: æ—¥æœ¬èªžã§çµæžœãŒå‡ºãªã„**
A: ImageNetã¯è‹±èªžã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã€‚ã§ã‚‚1000ç¨®é¡žã‚‚èªè­˜ã§ãã¦ã™ã”ã„ï¼

**Q: å·¥å ´ã®éƒ¨å“ã¯èªè­˜ã§ãã‚‹ï¼Ÿ**
A: ä¸€èˆ¬çš„ãªç‰©ä½“ã¯èªè­˜ã§ãã‚‹ã‘ã©ã€ç‰¹æ®Šãªéƒ¨å“ã¯é›£ã—ã„ã€‚ã ã‹ã‚‰è‡ªåˆ†ã§ãƒ¢ãƒ‡ãƒ«ã‚’ä½œã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚

---

## ðŸ“Š ä»Šæ—¥ã®ã¾ã¨ã‚

### å­¦ã‚“ã ã“ã¨
- [ ] æ©Ÿæ¢°å­¦ç¿’ã®åŸºæœ¬çš„ãªä»•çµ„ã¿
- [ ] Google Colabã®ä½¿ã„æ–¹
- [ ] ç”»åƒèªè­˜ã®ä½“é¨“
- [ ] AIãŒè¦‹ã¦ã„ã‚‹ç‰¹å¾´ã®å¯è¦–åŒ–

### é‡è¦ãªãƒã‚¤ãƒ³ãƒˆ
1. **ãƒ‡ãƒ¼ã‚¿ãŒå¤§äº‹**ï¼šãŸãã•ã‚“ã®è‰¯è³ªãªãƒ‡ãƒ¼ã‚¿ã§å­¦ç¿’
2. **å‰å‡¦ç†ãŒå¿…è¦**ï¼šç”»åƒã®ã‚µã‚¤ã‚ºã‚„å½¢å¼ã‚’çµ±ä¸€
3. **ç¢ºçŽ‡ã§åˆ¤å®š**ï¼š100%ã§ã¯ãªãã€å¯èƒ½æ€§ã‚’ç¤ºã™

### æ¬¡å›žäºˆå‘Š
æ¬¡å›žã¯ã€ŒTeachable Machineã€ã‚’ä½¿ã£ã¦ã€è‡ªåˆ†ã ã‘ã®AIãƒ¢ãƒ‡ãƒ«ã‚’ä½œã‚Šã¾ã™ï¼
å·¥å ´ã§ä½¿ãˆã‚‹ã€Œè‰¯å“/ä¸è‰¯å“ã€åˆ¤å®šAIã‚’ä½œã£ã¦ã¿ã¾ã—ã‚‡ã†ã€‚

---

## ðŸ  å®¿é¡Œ

1. **å®Ÿé¨“ãƒ¬ãƒãƒ¼ãƒˆ**
   - 5ç¨®é¡žä»¥ä¸Šã®ç”»åƒã§å®Ÿé¨“
   - çµæžœã‚’ã¾ã¨ã‚ã¦æå‡º

2. **èª¿æŸ»èª²é¡Œ**
   - ã€ŒTeachable Machineã€ã«ã¤ã„ã¦èª¿ã¹ã‚‹
   - ã©ã‚“ãªã“ã¨ãŒã§ããã†ã‹3ã¤è€ƒãˆã‚‹

3. **æº–å‚™**
   - æ¬¡å›žä½¿ã†ç”»åƒã‚’è€ƒãˆã‚‹ï¼ˆè‰¯å“/ä¸è‰¯å“ã®ã‚µãƒ³ãƒ—ãƒ«ï¼‰

**æå‡ºæ–¹æ³•**: 
- Google Colabã®ãƒªãƒ³ã‚¯ã‚’å…±æœ‰
- GitHubã®notebooksãƒ•ã‚©ãƒ«ãƒ€ã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰